<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>长尾问题</title>
      <link href="/2022/12/30/2022-12-30-chang-wei-wen-ti/"/>
      <url>/2022/12/30/2022-12-30-chang-wei-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="长尾问题"><a href="#长尾问题" class="headerlink" title="长尾问题"></a>长尾问题</h1><p>​在传统的分类任务中，训练数据往往都受到了人工的均衡，即不同类别样本数量没有明显差距。均衡的数据库将极大程度上简化了算法鲁棒性的要求，也一定程度上保障了模型的可靠性，但随着样本类别的增加维持各个类别之间的均衡将带来更大的成本。</p><p>​尤其是对于珍惜动物、与医疗上的罕见病例，部分类别的样本个数极为稀少，获取均衡的数据库几乎不可能。</p><p>​<img src="https://img-blog.csdnimg.cn/1229308b7cad4c33bc6c9a5070006e0b.png#pic_center" alt="img"></p><p>​</p><p>​目前解决长尾问题的解决方案有两种：重采样与重加权。</p><p>​重采样：<img src="C:\Users\de'l'l\AppData\Roaming\Typora\typora-user-images\image-20221130201514898.png" alt="image-20221130201514898"></p><p>​其中C是类别数量，i为样本总数。pj为从j类样本中取样的概率，q为指数。</p><p>​重加权：</p><p>​重加权反应在loss值上，由于loss的计算灵活性，重加权的计算更加简单。在此仅列举通用公式：</p><p>​<img src="C:\Users\de'l'l\AppData\Roaming\Typora\typora-user-images\image-20221130201924508.png" alt="image-20221130201924508"></p><p><a href="https://blog.csdn.net/weixin_42437114/article/details/120439298">(73条消息) Long-tailed Recognition (长尾问题)_连理o的博客-CSDN博客_长尾问题</a></p><p>​分类损失函数（Lcls）</p><h2 id="数据增广："><a href="#数据增广：" class="headerlink" title="数据增广："></a>数据增广：</h2><p>​图像数据准备对<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020">神经网络</a>与卷积神经网络模型训练有重要影响，<strong>当样本空间不够或者样本数量不足的时候会严重影响训练或者导致训练出来的模型泛化程度不够，识别率与准确率不高</strong>！本文将会带你学会如何对已有的图像数据进行<a href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA&amp;spm=1001.2101.3001.7020">数据增强</a>，获取样本的多样性与数据的多样性从而为训练模型打下良好基础。在不改变图像类别的情况下，增加数据量，能提高模型的泛化能力。<br>​    不同的视角，不同的大小，物体的形变问题，物体的遮挡问题，光照条件，背景复杂的问题，每一类中有多种形态的问题。<br>​而数据增广的思路也就是解决这个问题。数据增广如何增广就要从实际的问题出发，比如医学的图片基本上拍摄的时候视角是固定的，所以就不需要不同视角的增广。木纹检测中视角是不固定的，就需要不同的视角，不同的大小的增广，还需要应不同的光照条件对数据进行增广。</p><p>​如<strong>GistNet: a Geometric Structure Transfer Network for Long-Tailed Recognition</strong>文中使用了特殊的归一化思路，以将尾样本数据的方差逼近head样本。</p><p>​</p>]]></content>
      
      
      <categories>
          
          <category> 论文理论预读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文预读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12月1日组会</title>
      <link href="/2022/12/04/2022-12-4-12-yue-1-ri-zu-hui/"/>
      <url>/2022/12/04/2022-12-4-12-yue-1-ri-zu-hui/</url>
      
        <content type="html"><![CDATA[<h1 id="Large-Scale-Pre-training-for-Person-Re-identification-with-Noisy-Labels"><a href="#Large-Scale-Pre-training-for-Person-Re-identification-with-Noisy-Labels" class="headerlink" title="Large-Scale Pre-training for Person Re-identification with Noisy Labels"></a>Large-Scale Pre-training for Person Re-identification with Noisy Labels</h1><p>领域: 目标检测 行人重识别</p><h2 id="Noisy-Labels"><a href="#Noisy-Labels" class="headerlink" title="Noisy-Labels"></a>Noisy-Labels</h2><div></div>  在数据集中，一些样本的类别被错误的标注，比如猫狗分类集中猫被标注成了狗狗。这些样本被称为**noisy label**。与此相对的我们还经常听到**hard Sample**。**hard Sample**用来描述标注正确但是模型难以学习的样本，比如一只很像猫的狗，虽然难以分辨,但是它的标签是正确的。如果一只猫的标签是狗 那么它就是一个noisy label.<h2 id="Tracklet"><a href="#Tracklet" class="headerlink" title="Tracklet"></a>Tracklet</h2><div></div>  跟踪小片段，物体跟踪时会用到数据关联，整个连续的跟踪过程其实为由很多tracklet构成的，一般为5-6帧的集合。<h2 id="Re-ID-learning"><a href="#Re-ID-learning" class="headerlink" title="Re-ID learning"></a>Re-ID learning</h2><div></div>  行人重识别（Person Re-identification也称行人再识别，简称为ReID，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术；或者说，行人重识别是指在已有的可能来源与非重叠摄像机视域的视频序列中识别出目标行人。广泛被认为是一个图像检索的子问题。给定一个监控行人图像，检索跨设备下的该行人图像。在监控视频中，由于相机分辨率和拍摄角度的缘故，通常无法得到质量非常高的人脸图片。当人脸识别失效的情况下，ReID就成为了一个非常重要的替代品技术。ReID有一个非常重要的特性就是跨摄像头，所以学术论文里评价性能的时候，是要检索出不同摄像头下的相同行人图片。            <div align="center">                <img src="https://pic1.zhimg.com/v2-0c1a1b7dcec05fd4f298d3c5a3149f7f_720w.jpg?source=d16d100b">            </div><div></div>  常用方法:1. 基于表征学习的ReID方法:            <div align="center">                <img src="https://pic3.zhimg.com/80/v2-ee7edda90bd5e1a5f97cb83f79d6dda6_720w.webp">            </div>2. 基于度量学习的ReID方法:<br>   <div></div>  不同于特征学习，度量学习旨在通过网络学习出两张图片的相似度3. 基于局部特征的ReID方法:<br>   <div></div>  常用的提取局部特征的思路主要有图像切块、利用骨架关键点定位以及姿态矫正等等。（1）图片8切块是一种很常见的提取局部特征方式。如下图所示，图片被垂直等分为若干份，因为垂直切割更符合我们对人体识别的直观感受，所以行人重识别领域很少用到水平切割。   <div align="center">                <img src="https://pic4.zhimg.com/80/v2-7f318fbd8acd1736871c3268e844a8d3_720w.webp">    </div>4. 基于视频序列的ReID方法:<div></div>  基于视频序列的方法最主要的不同点就是这类方法不仅考虑了图像的内容信息，还考虑了帧与帧之间的运动信息等。代表方法:AMOC<br><div></div>  基于单帧图像的方法主要思想是利用CNN来提取图像的空间特征，而基于视频序列的方法主要思想是利用CNN 来提取空间特征的同时利用递归循环网络(Recurrent neural networks, RNN)来提取时序特征。<br><div align="center">                <img src="https://pic3.zhimg.com/80/v2-548b4735788e96cec985c6644cd5588e_720w.webp">    </div><div></div>  AMOC:输入 原始的图像序列和提取的光流序列<br><div></div>  核心思想: 网络除了要提取序列图像的特征，还要提取运动光流的运动特征。<div></div>  网络内容: 空间信息网络 + 运动信息网络<div align="center">                <img src="https://pic2.zhimg.com/80/v2-ca257bd81d5f9d724a8820af211183e5_720w.webp"></div><p>评价指标:</p><div></div>  **ROC**: ROC曲线是检测、分类、识别任务中很常用的一项评价指标。曲线上每个点反映着对同一信号刺激的感受性。具体到识别任务中就是，ROC曲线上的每一点反映的是不同的阈值对应的FP（false positive）和TP（true positive）之间的关系,如图所示。<div align="center">                <img src="https://pic1.zhimg.com/80/v2-02a39384b6f0e6e6520538532a047998_720w.webp"></div>       <b>CMC</b>:    CMC曲线是算一种top-k的击中概率，主要用来评估闭集中rank的正确率。[m1,m2,m3,m4,m5]为从高到低的概率，rk-1为第一个为正确标签，rk-2为前两个中包含标签，rk-5为前五个中包含正确标签。当检测多个人脸时，则取平均值，即mAP。<br><p>[1] (<a href="https://zhuanlan.zhihu.com/p/456060221">https://zhuanlan.zhihu.com/p/456060221</a>)</p><h2 id="Prototype-原型"><a href="#Prototype-原型" class="headerlink" title="Prototype(原型)"></a>Prototype(原型)</h2><div></div>  自然界的物体由各种属性组成，假设一个物体有k个属性x1,x2,...,xk,对应k个系数w1,w2,...,wk,则物体可以简单地表示为一个线性组合 $y=\sum_{j=1}^{k}w_{j}x_{j}$ 。这些属性x可以被成为原型(prototype)。属性的系数w为coefficients。<br><p>[2] (<a href="https://zhuanlan.zhihu.com/p/103512538">https://zhuanlan.zhihu.com/p/103512538</a>)</p><h2 id="Contrastive-learning-对比学习"><a href="#Contrastive-learning-对比学习" class="headerlink" title="Contrastive learning(对比学习)"></a>Contrastive learning(对比学习)</h2><div></div>  对比学习着重于学习同类实例之间的共同特征，区分非同类实例之间的不同之处。与生成式学习比较，对比式学习不需要关注实例上繁琐的细节，只需要在抽象语义级别的特征空间上学会对数据的区分即可，因此模型以及其优化变得更加简单，且泛化能力更强<div align="center">                <img src="https://pic3.zhimg.com/80/v2-3af2ec617b3534ef26336fe9866f402a_720w.jpg"></div><div></div>  对比学习的目标为学习一个编码器，此编码器对同类数据进行相似的编码，并使不同类的数据的编码结果尽可能的不同。<p>[3] (<a href="https://zhuanlan.zhihu.com/p/346686467">https://zhuanlan.zhihu.com/p/346686467</a>)</p><h2 id="Joint-Learning"><a href="#Joint-Learning" class="headerlink" title="Joint Learning"></a>Joint Learning</h2><div></div>  joint Learning是指模型中存在多个子任务，而我们可以将这些子任务一起训练。这么说起来有点抽象，可以举个简单的例子。比如在深度学习中，这个“深度”就可以理解为采用了多个模型进行Joint Learning，比如在许多NLP任务中，在进行模型训练前，我们会使用Word Embedding层（word to vector）对词向量进行编码，而Embedding层的参数，可以在和整个模型一起训练中得到，也可以单独对该层进行预训练，而后在该层参数确定后再拿来和模型剩余部分一起训练，这两种方法都属于Joint Learning的范畴，即Joint Learning中的子任务既可以和整个模型一起训练，也可以单独训练。而Joint Learning的含义则是将多个子模型集成为一个模型，完成最终的目标任务。<h2 id="Instances-实例"><a href="#Instances-实例" class="headerlink" title="Instances(实例)"></a>Instances(实例)</h2><div></div>  实例为目标和语义的结合。即，在图像中将目标检测出来，然后对每个像素打上标签。<h2 id="Landmarks-特征点"><a href="#Landmarks-特征点" class="headerlink" title="Landmarks(特征点)"></a>Landmarks(特征点)</h2><div></div>  图像灰度值发生剧烈变化的点或者在图像边缘上曲率较大的点<h2 id="Siamese-networks"><a href="#Siamese-networks" class="headerlink" title="Siamese networks"></a>Siamese networks</h2><div></div>  连体的神经网络，神经网络的连体通过共享权值来实现。<div align="center">                <img src="https://pic3.zhimg.com/v2-5070e28622a2f3ee9e3cb5d2259fae86_r.jpg"></div><div></div>  左右两个神经网络的权重一模一样。作用为衡量两个输入的相似成都。孪生神经网络有两个输入，将两个输入feed进入两个神经网络，这两个神经网络分别将输入映射到新的空间，形成输入在新的空间中的表示。通过loss的计算，评价两个输入的相似度。<h1 id="Lifelong-Unsupervised-Domain-Adaptive-Person-Re-identification-with-Coordinated-Anti-forgetting-and-Adaptation"><a href="#Lifelong-Unsupervised-Domain-Adaptive-Person-Re-identification-with-Coordinated-Anti-forgetting-and-Adaptation" class="headerlink" title="Lifelong Unsupervised Domain Adaptive Person Re-identification with Coordinated Anti-forgetting and Adaptation"></a>Lifelong Unsupervised Domain Adaptive Person Re-identification with Coordinated Anti-forgetting and Adaptation</h1><p>领域:目标检测 终身学习<br></p><h2 id="Fine-grained-细粒度识别"><a href="#Fine-grained-细粒度识别" class="headerlink" title="Fine-grained(细粒度识别)"></a>Fine-grained(细粒度识别)</h2><div></div>  相比基础的图像识别更加精细化一些。识别具体到小的种类。<h2 id="Anti-forgetting-遗忘问题"><a href="#Anti-forgetting-遗忘问题" class="headerlink" title="Anti-forgetting(遗忘问题)"></a>Anti-forgetting(遗忘问题)</h2><div></div>  灾难性遗忘: 在一个任务上训练出来的模型，如果在一个新任务上进行训练，就会大大降低原任务上的泛化性能，即之前的知识被严重遗忘了。<div></div>  样本遗忘:  在同一个任务的训练过程中，可能会有遗忘现象，一个样本可能在训练过程反复地学了忘，忘了学。<p>[4] (<a href="https://zhuanlan.zhihu.com/p/462224273">https://zhuanlan.zhihu.com/p/462224273</a>)</p><h2 id="Retrieval-based-tasks"><a href="#Retrieval-based-tasks" class="headerlink" title="Retrieval-based tasks"></a>Retrieval-based tasks</h2><div></div>  在外部知识库中搜索所需信息，结合外部知识以及语言模型本身。<h2 id="Source-domain"><a href="#Source-domain" class="headerlink" title="Source domain"></a>Source domain</h2><div></div>  概念来源于迁移学习，在迁移学习中，将已有的知识叫做源域(source domain),要学习的新知识叫做目标域(target domain）。研究如何将源域的知识迁移到目标域(target domain)上。<div></div>  源域（source domain): 与测试样本不同的领域，有丰富的监督信息。<div></div>  目标域(target domain): 测试样本所在的领域，无标签或者只有少量标签。<div align="center">                <img src="https://img-blog.csdnimg.cn/5364ca44799848b4913d8f7d398f79fe.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbGloZTIwMjE=,size_13,color_FFFFFF,t_70,g_se,x_16"></div><div></div>  红线表示source dataset的颜色信息值分布，蓝线表示target dataset的颜色信息值分布，两个域本来就有shift，导致evaluate模型的准确率降低，则颜色信息不适合选择特征。<div></div>  领域自适应旨在利用各种的feature transformation手段，学习一个域间不变的特征表达（特征自适应）。<p>[5] (<a href="https://blog.csdn.net/lihe4151021/article/details/123763606">https://blog.csdn.net/lihe4151021/article/details/123763606</a>)</p><h2 id="Knowledge-distillation-strategies-知识蒸馏"><a href="#Knowledge-distillation-strategies-知识蒸馏" class="headerlink" title="Knowledge distillation strategies(知识蒸馏)"></a>Knowledge distillation strategies(知识蒸馏)</h2><div></div>  一种模型压缩方法，将训练好的模型包含的知识，蒸馏提取到另一个模型里面去。不同于模型压缩中的剪枝和量化，知识蒸馏是通过构建一个轻量化的小模型，利用性能更好的大模型的监督信息，来训练这个小模型，以期达到更好的性能和精度。<p>功能:</p><ol><li><p>提升模型精度</p></li><li><p>降低模型时延，压缩网络参数</p></li><li><p>图片标签之间的域迁移</p></li><li><p>降低标注量。</p></li></ol><p>[6] (<a href="https://zhuanlan.zhihu.com/p/258390817">https://zhuanlan.zhihu.com/p/258390817</a>)</p><h2 id="Lifelong-Learning-终身学习"><a href="#Lifelong-Learning-终身学习" class="headerlink" title="Lifelong Learning(终身学习)"></a>Lifelong Learning(终身学习)</h2><div></div>  有两个目标：一是应对神经网络由于其自身的设计天然存在的灾难性遗忘问题&nbsp;(McCloskey and Cohen, 1989)，二则是使训练模型更为通用，即令模型同时具备可塑性（学习新知识的能力）和稳定性（对于旧知识的记忆能力）。<p>[7] (<a href="https://zhuanlan.zhihu.com/p/438766442">https://zhuanlan.zhihu.com/p/438766442</a>)</p><h2 id="A-triplet-loss"><a href="#A-triplet-loss" class="headerlink" title="A triplet loss"></a>A triplet loss</h2><div></div>  triplet loss 是深度学习的一种损失函数，主要是用于训练差异性小的样本，比如人脸等；主要功能是表征两个样本之间的相似性，功能同相似性度量。其次在训练目标是得到样本的embedding任务中，triplet loss 也经常使用，比如文本、图片的embedding。<h2 id="Reservoir-sampling-algorithm"><a href="#Reservoir-sampling-algorithm" class="headerlink" title="Reservoir sampling algorithm"></a>Reservoir sampling algorithm</h2><div></div>  蓄水池算法，用于解决大数据流中的数据采样问题。只遍历一次，每次都考虑一个问题：当前元素是否被选中，选中后替换之前选中的哪一个元素。<p>[8] (<a href="https://blog.csdn.net/wq3095435422/article/details/124413184">https://blog.csdn.net/wq3095435422/article/details/124413184</a>)</p><h1 id="Part-based-Pseudo-Label-Refinement-for-Unsupervised-Person-Re-identification"><a href="#Part-based-Pseudo-Label-Refinement-for-Unsupervised-Person-Re-identification" class="headerlink" title="Part-based Pseudo Label Refinement for Unsupervised Person Re-identification"></a>Part-based Pseudo Label Refinement for Unsupervised Person Re-identification</h1><h2 id="pseudo-label-伪标签"><a href="#pseudo-label-伪标签" class="headerlink" title="pseudo-label(伪标签)"></a>pseudo-label(伪标签)</h2><div></div>  来自于半监督学习，半监督学习的核心思想是通过借助无标签的数据来提升有监督过程中的模型性能。伪标签技术就是利用在已标注数据所训练的模型在未标注的数据上进行预测，根据预测结果对样本进行筛选，再次输入模型中进行训练的一个过程。<h2 id="Auxiliary-network"><a href="#Auxiliary-network" class="headerlink" title="Auxiliary network"></a>Auxiliary network</h2><div></div>  第一，辅助任务就像是模拟退火一样，提供了跳出局部最小值的可能。当然只是可能。<div></div>  第二，辅助任务能够优化基于batch的局部误差平面（loss surface）。<div></div>  第三，辅助任务是一种先验，能够更清晰的描述我们的任务。这个在现在众多的启发式网络改进里起了决定性的作用。<p>[9] (<a href="https://www.zhihu.com/question/424682292/answer/1606771422">https://www.zhihu.com/question/424682292/answer/1606771422</a>)</p><h2 id="Teacher-networks-学生-教师网络"><a href="#Teacher-networks-学生-教师网络" class="headerlink" title="Teacher networks:(学生-教师网络)"></a>Teacher networks:(学生-教师网络)</h2><div></div>  主要分为教师网络和学生网络，teacher结构相当于原始复杂的深度神经网络结构，student则是一种轻量级的网络结构；teacher会指导student到达简化参数之后的最好模型效果。在《Distilling the Knowledge in a Neural Network》中，teacher网络对student网络的指导，仅仅在网络输出结果的部分，并且以soft的类别概率分布的方式体现出来。这样student在进行学习的时候，相比于只提供类别的归属信息1或者0来说，它可以知道更多的信息，（虽然两个样本都被划为了1类，只能说明它们被预测为1类的概率大于被预测为0类的概率，但是它们被划分为1类的强弱信息是不知道的）<div align="center">    <img src="https://www.bing.com/images/blob?bcid=r0Qqx9UqUvcEnQ"></div><h2 id="Unsupervised-domain-adaptation"><a href="#Unsupervised-domain-adaptation" class="headerlink" title="Unsupervised domain adaptation"></a>Unsupervised domain adaptation</h2><div></div>  研究的重点为让模型可以适应不同领域之间的差异，减少域差对模型性能的影响。无监督领域自适应一般包含两个领域(数据集),即训练集是带标签的(有监督的)源域(source domain),和无监督的目标域(Target Domain)。任务目标是能够在无重叠视域的目标域中能够检索出同一行人。<h2 id="label-smoothing"><a href="#label-smoothing" class="headerlink" title="label smoothing"></a>label smoothing</h2><div></div>  标签平滑用来解决over-confident的问题，这类问题在对抗构建中尤为重要(GANS)。主要思想:避免模型过拟合，避免output有偏差值时，loss值趋向无穷大而逼迫模型去接近真实的label。<div></div>  在机器学习中，假设样本标签可能存在错误，避免“过分”相信训练样本的标签。当目标函数为交叉熵时，这一思想有非常简单的实现，称为标签平滑(Label smooting),即想办法告诉模型标签不一定正确。<div></div>  理论方式: 在每次迭代时，并不直接将$x_{i}$,$y_{i}$放入训练集，而是设置一个错误率ε，以1-ε的概率将$x_{i}$,$y_{i}$代入训练，以ε的概率将$x_{i}$,$1-y_{i}$代入训练。这样，模型在训练时，既有正确标签输入，又有错误标签输入，可以想象，如此训练出来的模型不会“全力匹配”每一个标签，而只是在一定程度上匹配。这样，如果真的出现错误标签，模型受到的影响就会更小。<h2 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h2><div></div>  目的:预测非球状结构<div></div>   算法原理: 将数据点分为核心点、边界点、噪音点。<div align="center">    <img src="https://www.bing.com/images/blob?bcid=Sx899eKcevcEqxcxoNWLuD9SqbotqVTdPwI"></div><p>[10] (<a href="https://www.jianshu.com/p/e594c2ce0ac0">https://www.jianshu.com/p/e594c2ce0ac0</a>)</p>]]></content>
      
      
      <categories>
          
          <category> 论文理论预读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文预读 目标检测 行人重识别 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
