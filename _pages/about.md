---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}
<!-- ========== æ¨ªæ¸ å››å¥æ ¼è¨€ ========== -->
<div class="motto-banner" markdown="1">
  <span class="motto-text">ä¸ºå¤©åœ°ç«‹å¿ƒï¼Œä¸ºç”Ÿæ°‘ç«‹å‘½ï¼Œä¸ºå¾€åœ£ç»§ç»å­¦ï¼Œä¸ºä¸‡ä¸–å¼€å¤ªå¹³</span>
  <span class="motto-author">â€” å¼ è½½ã€Šæ¨ªæ¸ å››å¥ã€‹</span>
</div>

<span class='anchor' id='about-me'></span>

My name is **Yuyang Hong** (æ´ªå®‡æ´‹).

My research interests include neural machine translation and computer vision. I have published more than 10 papers at top international AI conferences

---

# ğŸ“ Publications

<div class='paper-box'>
<div class='paper-box-image'><div><div class="badge">NeurIPS 2025</div>
<img src='images/Neurlps2025.png' alt="thumbnail" style="width:100%; height:180px; object-fit:cover; object-position:center; border-radius:6px; display:block;">
</div></div>
<div class='paper-box-text' markdown="1">

**Knowledge-based Visual Question Answering with Multimodal Processing, Retrieval and Filtering**  
[ğŸ“„ Paper](https://arxiv.org/abs/2510.14605) | [ğŸ’» GitHub](https://github.com/cqu-student/Wiki-PRF) | [ğŸ¤— HuggingFace](https://huggingface.co/hongyuyang23casia/Wiki-PRF-7B-Infoseek)

**Yuyang Hong**<sup>*</sup>, Jiaqi Gu<sup>*</sup>, Qi Yang, Lubin Fan<sup>â€ </sup>, Yue Wu, Ying Wang, Kun Ding<sup>â€ </sup>, Shiming Xiang, Jieping Ye

<span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span>

</div>
</div>

<div class='paper-box'>
<div class='paper-box-image'><div><div class="badge">arXiv 2025</div>
<img src='images/arxiv2025.png' alt="thumbnail" style="width:100%; height:180px; object-fit:cover; object-position:center; border-radius:6px; display:block;">
</div></div>
<div class='paper-box-text' markdown="1">

**Taming Modality Entanglement in Continual Audio-Visual Segmentation**  
[ğŸ“„ Paper](https://arxiv.org/abs/2510.17234) | [ğŸ’» GitHub](https://github.com/cqu-student/CMR) | [ğŸ¤— HuggingFace](https://huggingface.co/hongyuyang23casia/CMR)

**Yuyang Hong**<sup>*</sup>, Qi Yang, Tao Zhang, Zili Wang, Zhaojin Fu, Kun Ding, Bin Fan, Shiming Xiang

<span class='show_paper_citations' data='DhtAFkwAAAAJ:REPLACE_WITH_PAPER_ID'></span>

</div>
</div>

<!-- æ— å›¾è®ºæ–‡ 1: IF-Bench (å…±ä¸€æ ‡æ³¨) -->
<div class='paper-box-text-only' markdown="1">

<span class="paper-badge paper-badge-blue">arXiv 2025</span> **IF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting**  
[ğŸ“„ Paper](https://arxiv.org/abs/2512.09663)

Tao Zhang<sup>*</sup>, **Yuyang Hong**<sup>*</sup>, Yang Xia, Kun Ding, Zeyu Zhang, Ying Wang, Shiming Xiang, Chunhong Pan  
<sup>*</sup> Equal contribution

</div>

<!-- æ— å›¾è®ºæ–‡ 2: ICASSP 2026 -->
<div class='paper-box-text-only' markdown="1">

<span class="paper-badge paper-badge-blue">ICASSP 2026</span> **Enhanced Graph Transformer with Serialized Graph Tokens**  
[ğŸ“„ Paper](https://arxiv.org/abs/2602.09065)

Ruixiang Wang, **Yuyang Hong**, Shiming Xiang, Chunhong Pan

</div>

---

# ğŸ“– Education
- *2023.09 â€“ 2028.06 (Expected)*, PhD Candidate, Institute of Automation, Chinese Academy of Sciences, Beijing. 
- *2019.09 â€“ 2023.06*, Bachelor, Data Science and Big Data Technology, Chongqing University, Chongqing. 

---

# ğŸ’» Internships
- *2025.12 â€“ Present*, [Alibaba Cloud](https://cn.aliyun.com/), Hangzhou, China.
